{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MADE - Masked Autoencoder for Distribution Estimation"
      ],
      "metadata": {
        "id": "xnw_qBG47NdB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Paper:** [https://arxiv.org/pdf/1502.03509.pdf](https://arxiv.org/pdf/1502.03509.pdf), **Code:** [#](https://github.com/#), **Website:** [#](#)"
      ],
      "metadata": {
        "id": "H1WCIWiz7Phx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Abstract:** There has been a lot of recent interest in designing neural network models to estimate a distribution from a set of examples. We introduce a simple modification for autoencoder neural networks that yields powerful generative models. Our method masks the autoencoderâ€™s parameters to respect autoregressive constraints: each input is reconstructed only from previous inputs in a given ordering. Constrained this way, the autoencoder outputs can be interpreted as a set of conditional probabilities, and their product, the full joint probability. We can also train a single network that can decompose the joint probability in multiple different orderings. Our simple framework can be applied to multiple architectures, including deep ones. Vectorized implementations, such as on GPUs, are simple and fast. Experiments demonstrate that this approach is competitive with stateof-the-art tractable distribution estimators. At test time, the method is significantly faster and scales better than other autoregressive estimators."
      ],
      "metadata": {
        "id": "upMRP4o9AtDU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Setup.\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as D\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import PIL\n",
        "import tqdm"
      ],
      "metadata": {
        "cellView": "form",
        "id": "qxUcGc_XClkg"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Background"
      ],
      "metadata": {
        "id": "rMICE6GAWSkT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://stackabuse.s3.amazonaws.com/media/image-reconstruction-and-denoising-with-autoencoders-in-python-and-keras-3.png)"
      ],
      "metadata": {
        "id": "L8yWh3V-Wdbt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a traditional autoencoder all units are densely connected to all other units of the previous layer. This facilitates full *visibility* between the reconstruction $\\mathbf{\\hat x}$ and the input $\\mathbf{x}$, i.e., information about $x_i$ can flow to all output positions. One drawback of this scheme is that the latent space can become *trivial*. When given enough capacity, the network can learn a simple *copy* function that simply *restates* the input condition rather than utilize *statistical* redundancies/features of the data to perform compression. In these cases, the output likelihoods are 100% for any input, meaning they fail to act as properly normalized probabilities. One way to overcome this is by enforcing autoregression. In this case, each output $\\hat x_i$ is a *conditional probability* $\\hat x_i = p_\\theta(x_i|x_1,\\dots,x_{i-1})$. Then the full reconstruction can be expressed as\n",
        "\n",
        "$$p_\\theta(\\mathbf{x}) = \\prod_{i = 1}^D p_\\theta(x_i|x_1,\\dots,x_{i-1}) = \\prod_{i=1}^D \\hat x_i.$$\n",
        "\n",
        "Since each $\\hat x_i \\in [0, 1]$, this probability will always remain valid."
      ],
      "metadata": {
        "id": "Wr50M10JXxEp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To enforce autoregressivity, we must prevent $\\hat x_i$ from accessing information about $x_{j \\ge i}$. We can do this by zeroing connections in the encoder and decoder matricies so as to prohibit non-causal paths. For example, consider an autoencoder with three input units, four hidden units, and three output units. Suppose we wish to enforce $p(x_1)p(x_2|x_1)p(x_3|x_1,x_2)$. For $\\hat x_1$ we must \"cut all ties\" since it gives an *unconditional* likelihood. For $\\hat x_2$, we only allow information from $x_1$. For $\\hat x_3$, we only allow information from $x_1$ and $x_2$. The diagram below shows the autoencoder with certain connections cut to preserve causality:\n",
        "\n",
        "![](https://i.ibb.co/t2kwPLS/MADE.png)\n",
        "\n",
        "Here, the numbers on each hidden unit denote the inputs on which it depends. In this specific scenario, the first unit of the first hidden layer depends only on $x_1$, whereas the remaining units of that layer depend on both $x_1$ and $x_2$. No unit is permitted to depend on all inputs since that would defeat the autogressive property. In the second hidden layer, we see two hidden units depending only on $x_1$, while two others depend on both $x_1$ and $x_2$. The choice of which hidden units depend on which inputs is rather subjective. The only constraint is that no hidden depends on all inputs. At the output layer, we see that $y_1 = \\hat x_1$ depends on nothing. Meanwhile, $y_2$ depends only on $x_1$ whereas $y_3$ depends only on $x_1$ and $x_2$. In the next section we describe a general masking formula."
      ],
      "metadata": {
        "id": "sAImughxav27"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2. Generating Masks"
      ],
      "metadata": {
        "id": "P6zcqNMIvZkq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To generate masks for each layer, we firstly assign each unit $z_k^l$ a number between $1$ and $D - 1$ (where $D$ is the dimensionality of the input). Denote this by $\\text{ID}^l(k)$. We then ensure that for each connection, $z_j^{l-1} \\to z_k^l$, we have that $\\text{ID}^l(k) \\ge \\text{ID}^{l-1}(j)$. At the input layer we assign the inputs IDs by $\\text{ID}^0(k) = k$. We do the same for the output layer."
      ],
      "metadata": {
        "id": "tLFP7k3Jvb6x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This inductively ensures that all units in layer $l$ will only be connected to units in layer $l-1$ having a connection to past inputs. To actually generate the masks, we simply apply the above rule for each position. Namely, the mask for the weights between layer $l-1$ and $l$ is given by\n",
        "\n",
        "$$\\mathbf{M}^{l}_{k', k} = \\begin{cases}1 & \\text{if } \\text{ID}^l(k') \\ge \\text{ID}^{l-1}(k) \\\\ 0 & \\text{otherwise}\\end{cases}.$$\n",
        "\n",
        "For the output layer we replace $\\ge$ with $\\gt$."
      ],
      "metadata": {
        "id": "LG6bGwClxFgr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Data"
      ],
      "metadata": {
        "id": "33CIYOBi9VAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Download the MNIST dataset.\n",
        "\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.PILToTensor(),\n",
        "    transforms.Lambda(lambda x: x / 255.),\n",
        "])\n",
        "\n",
        "train_dataset = MNIST(root='.', train=True, download=True, transform=transform)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ilFwX1cczg-s"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown\n",
        "\n",
        "transforms.ToPILImage()(train_dataset[0][0]).resize((200, 200), 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "cellView": "form",
        "id": "BmEorrVL0A7-",
        "outputId": "bb66adfc-f8fc-4875-fd7b-8e2978e6e376"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=200x200>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAAAAACIM/FCAAAC9klEQVR4nO2dTYhOURjHXx9ZECYbakpiQYlYoKQmaZJiMbGhbLBDVjZ2FqSwMLKwmrKQLVaUz4VS8rEhex87XjT5iGHxf9506na799x7p6dnfr/Nr/d+nHP/PXW63XPmTK8HAAAAAAAAAAAAAAAAAPCfWd00O0daXHTumDTffq6WjkoXpP3SD+mcdLqsx9m1n9EpBPEGQbwRJsjc7DuXS/OkrXZ0mzQk7a3QzjtpXBqTvkmvpEcVmglTEYJ4gyDeCBMk4+13o3RPKnzBrcKU+ZA0mZz8IH2W3lZoLkxFCOINgngjTJCM4XeJ9FRaWeEOu7QvbZd+2cns8TslTEUI4g2CeCNMkIyPD5+kk9Ju6YWdHE8ufSmNSvaCu1Y6Ub/nMsJUhCDeIIg3wgRpPPW2SLKPtb2r0mHpoHS9aScVCFMRgniDIN4giDfy5xCNr+nPL8mvI9INaarXIWEqQhBvEMQbYYK0vYJugXRbGpF2SXdb7ishTEUI4g2CeCNMkI4WMK+Snkt96YH0TLpil/5tp8cwFSGINwjijTBBOhp+DVuOPCEtTM6dMl+TPjbsKkxFCOINgngjTJBuh19jnXRR2pGetFnHM9L73D7CVIQg3iCIN8IEmZbh1xiS9kgT6RPcl0ZzGw9TEYJ4gyDeCBNkOofflJ9mW3vxW9opPazdXJiKEMQbBPEGQbzReAVdFdZL+6RNhT2/lh7n9hGmIgTxBkG8ESZIR8OvbSx3XLKpxGWFl/6RbA4xe5FzmIoQxBsE8UaYIG19RRkMrQck29BzRckdtpBuMHl4q+EDhKkIQbxBEG+ECZI//C6VbE+Ny3Z0TckdthfSeemmHW3pj/rCVIQg3iCIN8IEqTP82uZztuRtg1S6B90TyZbO3ZG+1+iyOmEqQhBvEMQbYYKUD79bJNtubrM0XHaHja2XpLPSZPG1rRKmIgTxBkG8ESZI+dTbWKKUN5JtU2ETaIN/39Rv+Fj1CVMRgniDIN4gCAAAAAAAAADAjOIfxWhM3nfnBlIAAAAASUVORK5CYII=\n"
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Model"
      ],
      "metadata": {
        "id": "GGm3DNh_9Yzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Mask generation.\n",
        "\n",
        "from typing import Tuple\n",
        "\n",
        "def get_layer_mask(this_layer_ids: Tuple, next_layer_ids: Tuple, is_output: bool = False) -> torch.Tensor:\n",
        "\n",
        "    this_layer_size = len(this_layer_ids)\n",
        "    next_layer_size = len(next_layer_ids)\n",
        "\n",
        "    mask = torch.ones((next_layer_size, this_layer_size))\n",
        "\n",
        "    # Zero out non-causal connections.\n",
        "\n",
        "    for i, this_id in enumerate(this_layer_ids):\n",
        "        for j, next_id in enumerate(next_layer_ids):\n",
        "\n",
        "            if is_output:\n",
        "                mask[j, i] = int(next_id > this_id)\n",
        "            else:\n",
        "                mask[j, i] = int(next_id >= this_id)\n",
        "    return mask.to(float)"
      ],
      "metadata": {
        "id": "cjVFYYX40bH2"
      },
      "execution_count": 418,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some quick tests show that our masking code matches the diagrams in the paper."
      ],
      "metadata": {
        "id": "6z0UpETF3PzU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_layer_mask((3, 1, 2), (2, 1, 2, 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGJmBUJx1qiZ",
        "outputId": "12148827-3ccb-4ae1-b384-9f009a7b7458"
      },
      "execution_count": 343,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1., 1.],\n",
              "        [0., 1., 0.],\n",
              "        [0., 1., 1.],\n",
              "        [0., 1., 1.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 343
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_layer_mask((2, 1, 2, 2), (1, 2, 2, 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agMQnUYS3DV1",
        "outputId": "0ee85af8-deac-45a6-c293-b4d282011468"
      },
      "execution_count": 344,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1., 0., 0.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [0., 1., 0., 0.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 344
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_layer_mask((1, 2, 2, 1), (3, 1, 2), is_output=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29quuFQR3H0A",
        "outputId": "a770e504-047c-4f73-c515-3edad74b430b"
      },
      "execution_count": 345,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [1., 0., 0., 1.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 345
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Unit ID assignment.\n",
        "\n",
        "def get_hidden_layer_ids(layer_size: int, input_size: int) -> Tuple:\n",
        "\n",
        "    return tuple(torch.randint(low=1, high=input_size, size=(layer_size,)).tolist())"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ndmmQCC77Nv8"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Model.\n",
        "\n",
        "import math\n",
        "\n",
        "\n",
        "class MaskedLinear(nn.Module):\n",
        "    \"\"\"A masked linear layer.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_features: int,\n",
        "        out_features: int,\n",
        "        input_layer_size: int,\n",
        "        previous_layer_ids: Tuple,\n",
        "        this_layer_ids: Tuple = None,\n",
        "        is_output_layer: bool = False,\n",
        "    ) -> None:\n",
        "        \"\"\"Initializes the module.\"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "\n",
        "        std = math.sqrt(2 / (in_features + out_features))\n",
        "        self.weight = nn.Parameter(std * torch.randn((out_features, in_features)))\n",
        "        self.bias = nn.Parameter(torch.zeros(out_features))\n",
        "        self.layer_ids = this_layer_ids or get_hidden_layer_ids(out_features, input_layer_size)\n",
        "\n",
        "        self.mask = get_layer_mask(previous_layer_ids, self.layer_ids, is_output=is_output_layer)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Forward pass.\"\"\"\n",
        "\n",
        "        return x @ (self.weight * self.mask).T + self.bias\n",
        "\n",
        "\n",
        "class MADE(nn.Module):\n",
        "    \"\"\"MADE.\"\"\"\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        \"\"\"Initializes the module.\"\"\"\n",
        "\n",
        "        super(MADE, self).__init__()\n",
        "\n",
        "        input_size = 28 * 28\n",
        "        hidden_size = 500\n",
        "        input_layer_ids = tuple(range(1, input_size + 1))\n",
        "\n",
        "        # Encoder.\n",
        "\n",
        "        self.linear_0 = MaskedLinear(input_size, hidden_size, input_size, input_layer_ids)\n",
        "        self.linear_1 = MaskedLinear(hidden_size, hidden_size, input_size, self.linear_0.layer_ids)\n",
        "        #self.linear_2 = MaskedLinear(hidden_size, hidden_size, input_size, self.linear_1.layer_ids)\n",
        "\n",
        "        # Decoder.\n",
        "\n",
        "        #self.linear_3 = MaskedLinear(hidden_size, hidden_size, input_size, self.linear_2.layer_ids)\n",
        "        self.linear_4 = MaskedLinear(hidden_size, hidden_size, input_size, self.linear_1.layer_ids)\n",
        "        self.linear_5 = MaskedLinear(hidden_size, input_size, input_size, self.linear_4.layer_ids, is_output_layer=True, this_layer_ids=input_layer_ids)\n",
        "\n",
        "    def encode(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Encodes an observation.\"\"\"\n",
        "\n",
        "        x = F.relu(self.linear_0(x))\n",
        "        x = F.relu(self.linear_1(x))\n",
        "        #x = F.relu(self.linear_2(x))\n",
        "\n",
        "        return x\n",
        "\n",
        "    def decode(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Decodes a latent.\"\"\"\n",
        "\n",
        "        #x = F.relu(self.linear_3(x))\n",
        "        x = F.relu(self.linear_4(x))\n",
        "        x = F.sigmoid(self.linear_5(x))\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"Forward pass.\"\"\"\n",
        "\n",
        "        z = self.encode(x)\n",
        "        y = self.decode(z)\n",
        "\n",
        "        return y, z\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "bFm2kCu4BPi0"
      },
      "execution_count": 471,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Training"
      ],
      "metadata": {
        "id": "Wqw_KiHr9bph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MADE()"
      ],
      "metadata": {
        "id": "ipb6m1C4Sx7X"
      },
      "execution_count": 472,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)"
      ],
      "metadata": {
        "id": "YlOzbYQ3SzLy"
      },
      "execution_count": 473,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "batch_size = 256\n",
        "\n",
        "train_dataloader = D.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    losses = []\n",
        "\n",
        "    for i, (x, _) in enumerate(train_dataloader):\n",
        "\n",
        "        x = x.view(-1, 28 * 28).to(float)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        reconstruction, _ = model(x)\n",
        "        loss = F.binary_cross_entropy(reconstruction, x)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        if (i % 10) == 0:\n",
        "            mean_loss = sum(losses) / len(losses)\n",
        "            losses.clear()\n",
        "\n",
        "            print(f'epoch {epoch}, batch {i} - loss: {mean_loss}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oQ6LWo_LSoBd",
        "outputId": "13daa97a-6053-4637-e808-3522ee8bc5b9"
      },
      "execution_count": 474,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0, batch 0 - loss: 0.6929835790898319\n",
            "epoch 0, batch 10 - loss: 0.46745321620756075\n",
            "epoch 0, batch 20 - loss: 0.3506420630227653\n",
            "epoch 0, batch 30 - loss: 0.31578611350407304\n",
            "epoch 0, batch 40 - loss: 0.29594236130325796\n",
            "epoch 0, batch 50 - loss: 0.2820177387806012\n",
            "epoch 0, batch 60 - loss: 0.2685697346907798\n",
            "epoch 0, batch 70 - loss: 0.26111962249667553\n",
            "epoch 0, batch 80 - loss: 0.24875614514903663\n",
            "epoch 0, batch 90 - loss: 0.24581731115493538\n",
            "epoch 0, batch 100 - loss: 0.24068534733198424\n",
            "epoch 0, batch 110 - loss: 0.23565408294537377\n",
            "epoch 0, batch 120 - loss: 0.23130583467407878\n",
            "epoch 0, batch 130 - loss: 0.2243826891130265\n",
            "epoch 0, batch 140 - loss: 0.22193664080563041\n",
            "epoch 0, batch 150 - loss: 0.21973851055494992\n",
            "epoch 0, batch 160 - loss: 0.21085281150962176\n",
            "epoch 0, batch 170 - loss: 0.2053418403599546\n",
            "epoch 0, batch 180 - loss: 0.2039557638904229\n",
            "epoch 0, batch 190 - loss: 0.19993921577492915\n",
            "epoch 0, batch 200 - loss: 0.19922118326968058\n",
            "epoch 0, batch 210 - loss: 0.19762407125309042\n",
            "epoch 0, batch 220 - loss: 0.1943046897084008\n",
            "epoch 0, batch 230 - loss: 0.19279816594109123\n",
            "epoch 1, batch 0 - loss: 0.18591324336544104\n",
            "epoch 1, batch 10 - loss: 0.1904349393540105\n",
            "epoch 1, batch 20 - loss: 0.18823930748981935\n",
            "epoch 1, batch 30 - loss: 0.186268482567794\n",
            "epoch 1, batch 40 - loss: 0.1851675628014739\n",
            "epoch 1, batch 50 - loss: 0.18385238083395078\n",
            "epoch 1, batch 60 - loss: 0.18188889778740763\n",
            "epoch 1, batch 70 - loss: 0.1813730976365405\n",
            "epoch 1, batch 80 - loss: 0.1797537276076627\n",
            "epoch 1, batch 90 - loss: 0.17751958120511324\n",
            "epoch 1, batch 100 - loss: 0.17580691886640926\n",
            "epoch 1, batch 110 - loss: 0.1754470483913313\n",
            "epoch 1, batch 120 - loss: 0.1744338514233919\n",
            "epoch 1, batch 130 - loss: 0.17418321229675177\n",
            "epoch 1, batch 140 - loss: 0.1716259960581404\n",
            "epoch 1, batch 150 - loss: 0.17312670647576225\n",
            "epoch 1, batch 160 - loss: 0.16937962165962933\n",
            "epoch 1, batch 170 - loss: 0.16930178603448381\n",
            "epoch 1, batch 180 - loss: 0.1689282108276305\n",
            "epoch 1, batch 190 - loss: 0.16773428552041586\n",
            "epoch 1, batch 200 - loss: 0.16670962152931207\n",
            "epoch 1, batch 210 - loss: 0.1654046773710127\n",
            "epoch 1, batch 220 - loss: 0.16588284156541352\n",
            "epoch 1, batch 230 - loss: 0.16535169466992633\n",
            "epoch 2, batch 0 - loss: 0.1649128515704747\n",
            "epoch 2, batch 10 - loss: 0.16356436179527803\n",
            "epoch 2, batch 20 - loss: 0.16234637565002866\n",
            "epoch 2, batch 30 - loss: 0.16298454308099122\n",
            "epoch 2, batch 40 - loss: 0.16102237102487207\n",
            "epoch 2, batch 50 - loss: 0.16104368800681512\n",
            "epoch 2, batch 60 - loss: 0.16057658764907584\n",
            "epoch 2, batch 70 - loss: 0.15951651428227098\n",
            "epoch 2, batch 80 - loss: 0.15885486750416353\n",
            "epoch 2, batch 90 - loss: 0.1588607243971108\n",
            "epoch 2, batch 100 - loss: 0.15716427463252497\n",
            "epoch 2, batch 110 - loss: 0.1587363557775724\n",
            "epoch 2, batch 120 - loss: 0.15648758071056673\n",
            "epoch 2, batch 130 - loss: 0.15626025482918002\n",
            "epoch 2, batch 140 - loss: 0.15666573515085677\n",
            "epoch 2, batch 150 - loss: 0.1573413848121037\n",
            "epoch 2, batch 160 - loss: 0.15419099655151008\n",
            "epoch 2, batch 170 - loss: 0.15456971210719841\n",
            "epoch 2, batch 180 - loss: 0.15668338597015946\n",
            "epoch 2, batch 190 - loss: 0.15464175995023768\n",
            "epoch 2, batch 200 - loss: 0.15413075914403437\n",
            "epoch 2, batch 210 - loss: 0.15268442608492597\n",
            "epoch 2, batch 220 - loss: 0.15310183449401643\n",
            "epoch 2, batch 230 - loss: 0.15177813941337256\n",
            "epoch 3, batch 0 - loss: 0.15023943707138473\n",
            "epoch 3, batch 10 - loss: 0.1532502901536199\n",
            "epoch 3, batch 20 - loss: 0.1522301100611335\n",
            "epoch 3, batch 30 - loss: 0.14962846612532585\n",
            "epoch 3, batch 40 - loss: 0.14962102565040653\n",
            "epoch 3, batch 50 - loss: 0.1505115883951351\n",
            "epoch 3, batch 60 - loss: 0.15052131975282995\n",
            "epoch 3, batch 70 - loss: 0.15072501827317855\n",
            "epoch 3, batch 80 - loss: 0.1481644832611029\n",
            "epoch 3, batch 90 - loss: 0.14848135453835223\n",
            "epoch 3, batch 100 - loss: 0.14903507927434598\n",
            "epoch 3, batch 110 - loss: 0.14823587563730417\n",
            "epoch 3, batch 120 - loss: 0.14784723205124933\n",
            "epoch 3, batch 130 - loss: 0.14654545471672029\n",
            "epoch 3, batch 140 - loss: 0.14836301756990744\n",
            "epoch 3, batch 150 - loss: 0.14842891453192164\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-474-acd2e3a17893>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mreconstruction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreconstruction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-471-6fd1786698f5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-471-6fd1786698f5>\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m#x = F.relu(self.linear_3(x))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-471-6fd1786698f5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;34m\"\"\"Forward pass.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1599\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward_pre_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1601\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1602\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'_parameters'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m             \u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_parameters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Evaluation"
      ],
      "metadata": {
        "id": "TjtNnGQg9dS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transforms.ToPILImage()(x[201].view(28, 28)).resize((200, 200),0)"
      ],
      "metadata": {
        "id": "bRBjQBde_g15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "a32b1dcd-998b-4d5a-e98c-6e783b0669db"
      },
      "execution_count": 596,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=200x200>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAAAAACIM/FCAAADDElEQVR4nO2cTahNURiGj5+U/A0MKOV2Rwakm+5EMZAiuWMGDE5KpJQoZYyYCAMGcg0VU2FgSpGSARPlr4QYIFLyO3i/PVhZHWvtfQ+fr+eZPO191t5rvX21zm6fdVavBwAAAAAAAAAAAADglGldbzBX2txLvC1pM116Lh2VJu3DH11HkPTx/0MQbxDEG2GCtJh+Z0lrpX3SpoJOfiYn55s/148gR5iKEMQbBPFGmCAz6y/ZJZ3MfnhTOi69kJZIV5OW283n6keQI0xFCOINgngjTJCap9++dD45+U7aYYfXpW9Jm4XSbWk0Odn7UDGCAYSpCEG8QRBvhAlS8/SbbTsh3Rl04VZpNDn5taLnAsJUhCDeIIg3wgQpmn4XSzvbdjKRHD2Rvre9W54wFSGINwjijTBBiqbfOdKI9EpaJb0fdKG9190oPZU2SF+KxldMmIoQxBsE8QZBvFH0PfJY2pMcvR10xXppS3LyrvSsbGSVhKkIQbxBEG+ECdJ5AXOeG9I66aO0Rno4lB7DVIQg3iCIN8IEabGCroT7kk2/tlb5gnRROmtNp+i3xDAVIYg3COKNMEGG9PRrnJL60rxsm9fSEclee9f/wBimIgTxBkG8ESbIcKdfY4VkK+iWS82CkJGk6TVpt/SyvI8wFSGINwjijTBB/sr0m2WReb90IPnwdO7kQMJUhCDeIIg3wgT5d9NvwwzpljQuPZDGym8TpiIE8QZBvEEQb3T+DdHekNhWdM2/XN6U38DeV9v/x8fbjiNMRQjiDYJ4I0yQ9tOvzbv2+G3/lWl2SJr8rfmfGGs9EBGmIgTxBkG8ESZI++l3dqKGQ5JNyo+k7CbLtpNo74xke4jaerq91cMJUxGCeIMg3ggTpPNL7CtSfgfmy9Kx5KQt4Thohysl24rOJuzV1eMIUxGCeIMg3ggTpPP0aysx+nZoLx+W5jpJN8BvuCddkk60HUeYihDEGwTxRpggU72EY5lks3BfWiCl028z0R6WPnXsOExFCOINgngjTBAAAAAAAAAAAAAAALf8ApztTUVoCP9nAAAAAElFTkSuQmCC\n"
          },
          "metadata": {},
          "execution_count": 596
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transforms.ToPILImage()(model(x[201].view(-1, 28*28))[0].view(28, 28)).resize((200, 200),0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "nzRTyQ-Nb9lV",
        "outputId": "bd022473-09b9-4762-c532-25fb8e05552b"
      },
      "execution_count": 595,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=200x200>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAAAAACIM/FCAAAEfElEQVR4nO2du49VVRTG7zwYEBXCQxFUMrwqSKCgIWpMHGNDoAILKsMfYUdHSWFiRUcPsZBQUNAogQQjAeIDYqImhIBBwtuLwzhSfL9dLLJzc+9FxnV3vl/z5Zxz9znz3Z2ss+46a58Zm+q8fGYX4BrjC3CNBcFGsmEj2WjGiDHGmP+FsZd6vrGaPMe/PWQAmrkh2kg2bCQbzRh54fD7XGitBtzxIDCPxoA7X9vqh2ZmxEayYSPZsJFsDHEfifeIiSCdRWFzKsikhHtEqWzPSZ7W5B9JvLnUaWZGbCQbNpKNZoz0FX5jNk5oJdAukbzaCfq6ZJmE8Ls4nO0JIx5K7koeh51dyVyQEpQjzcyIjWTDRrLRjJHJnkdjostnCaaHJO9JNjFiSRjxt+RhEALtMUZclPwpKSF2YJqZERvJho1koxkjvbNfbJLorpK8FWSNpBQf7ki+kXTDwbWSTyTTjPheciaM76fcUP1TRx8byYaNZKMZI/Xst+wlpz0g+UzymoRA+bXkMCPuS4ibfE1vSPaFrZ8Z8ZVkNgwcnGZmxEayYSPZaMZI7+IDxYPrkp8khN/fJSclpZJbzZcPSj4K5/4WnehUiFWPftrqmpkRG8mGjWSjGSP18Fsebt2UXJUslayX8CBtWnKLESskM5LtknVhBFXe8hXGDooYvhlBZlxCfLU+3MyM2Eg2bCQbNpKN+n2kJMyk8b9JLoWd3GNWSqYZwV3hcRjIRXi+yH3kfUb8FU5+L1yjW/2rqjQzIzaSDRvJRjNGhuigo4WDYsorko189EPJOxI66N6U3JAcl5xlxCMJLcteh2gj2bCRbDRjpHcRGwiG1Fa6QQjGROHOAwnfz2YJTw2Jwpck1zrhrIR4orBbOEYfG8mGjWSjr/BbZTycoCzGozuZZrnq+pGZsLNzXvKjhBaQ6ro9Fx9GChvJho1k44XfwhEf+pWAS3czHXjLJR9ISJTfZgQL/r6TnJCQGldX8dXDcDMzYiPZsJFsNGNkiPAb0176OlZzkAx3UfgovRc8j6O+sJURuyUEbJLgUxLqwvSHEIwdfkcDG8mGjWRjkOJD7HWLeS5bpVxAZYG4Sykhri1hqxykPjwt2Sm5LPmjjz+umRmxkWzYSDZsJBuD3Ee4AZCG35N0w7FycC7urV3yNpv8Dtgg2SLh18A5yYMeZys0MyM2kg0byUYzRoZ4hsgQ1hi+K6FCUhaHx4IJmXp8PzR9zJ1fJCxS5OfAoyBxOWKdZmbERrJhI9loxkhf4ZfwR2WaRrjPJbxag3S1vNLoS8kFCQtH+NKIsHsZ8amEtYosHCHSxlci9aSZGbGRbNhINpoxMkgDM1GQzPYHCeVmFoyUpo39km0SejdIlAnfZak59W7KFSwKPBou5ex3FLGRbNhINobvoONRIjH1CHt3SYjq5LKUd8mep+KVYy1ij+SKxOtHRhgbyYaNZOO/+jeCZTXIxxKy3x2SteEzFIR/ZcQXktMSuuQGfw9+MzNiI9mwkWw0Y8QYY4wxxhhjjDHGGGOMScsz6y3BYLEc0B4AAAAASUVORK5CYII=\n"
          },
          "metadata": {},
          "execution_count": 595
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Sample from the model. TODO: make this more efficient.\n",
        "\n",
        "import random\n",
        "\n",
        "def sample():\n",
        "\n",
        "    input_size = 28 * 28\n",
        "    model_input = torch.zeros(input_size).to(float)\n",
        "\n",
        "    for i in range(input_size):\n",
        "        distribution = model(model_input.view(1, input_size))[0].view(input_size)\n",
        "        p_i = distribution[i].item()\n",
        "\n",
        "        model_input[i] = float(random.random() < p_i)\n",
        "\n",
        "    return model_input"
      ],
      "metadata": {
        "cellView": "form",
        "id": "QXjkOOa1f6nG"
      },
      "execution_count": 622,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transforms.ToPILImage()(sample().view(28, 28)).resize((200, 200), 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "6li4OUg1hj0y",
        "outputId": "aa6c98a3-b724-4d6e-e61c-e5c066821a1d"
      },
      "execution_count": 638,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=200x200>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAAAAACIM/FCAAABx0lEQVR4nO3czU7DMBQG0Qbx/q8cFt0QZEX+TccfczZI0IaOLN2aJOV4vZ3vL8drV1+ffgGzGEJjCE1MiCRJkvR/PHK24YkzGzF/jxhCYwiNITQfOGu95l0lZkUMoTGEJibkyfG7dDcfsyKG0BhCExOydvyez/2umBUxhMYQmpiQ2SPxusM9Sw/587NJryBmRQyhMYQmJuR7zWGLc7fmod3DOGZFDKExhCYmZNbutzxvi0c/i48ZncIxK2IIjSE0MSHDu9+aYVp8SMPBa54RsyKG0BhCYwjN8Da+Yf9+fcZR/G7xMOX3qquYFTGExhCamJCO8VtzgrrisOVriN37/5gVMYTGEJqYkFnjd/KtILd3grj73YIhNIbQtIzNSdvemt9xey7c8bsFQ2gMoRm+hlhx0bBD+w47ZkUMoTGEJiakardaMVvXnHxoOHjMihhCYwhNTMis3e+w4sBt2FPHrIghNIbQGELT/z6y9CM07SdlYlbEEBpDaGJC+sdv+3+Ua3iGn0PcnyE0htAM38Kx5hqi43d/htAYQjP7Drq1r+BGzIoYQmMITUzI8OdH2m81XiNmRQyhMYQmJkSSJEmSJEmSJEmSfvsB/MEtKWDls+cAAAAASUVORK5CYII=\n"
          },
          "metadata": {},
          "execution_count": 638
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xB-CwvmKijl0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}