{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MADE - Masked Autoencoder for Distribution Estimation"
      ],
      "metadata": {
        "id": "xnw_qBG47NdB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Paper:** [https://arxiv.org/pdf/1502.03509.pdf](https://arxiv.org/pdf/1502.03509.pdf), **Code:** [#](https://github.com/#), **Website:** [#](#)"
      ],
      "metadata": {
        "id": "H1WCIWiz7Phx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Abstract:** There has been a lot of recent interest in designing neural network models to estimate a distribution from a set of examples. We introduce a simple modification for autoencoder neural networks that yields powerful generative models. Our method masks the autoencoder’s parameters to respect autoregressive constraints: each input is reconstructed only from previous inputs in a given ordering. Constrained this way, the autoencoder outputs can be interpreted as a set of conditional probabilities, and their product, the full joint probability. We can also train a single network that can decompose the joint probability in multiple different orderings. Our simple framework can be applied to multiple architectures, including deep ones. Vectorized implementations, such as on GPUs, are simple and fast. Experiments demonstrate that this approach is competitive with stateof-the-art tractable distribution estimators. At test time, the method is significantly faster and scales better than other autoregressive estimators."
      ],
      "metadata": {
        "id": "upMRP4o9AtDU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Setup.\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as D\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import PIL\n",
        "import tqdm"
      ],
      "metadata": {
        "cellView": "form",
        "id": "qxUcGc_XClkg"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Background"
      ],
      "metadata": {
        "id": "rMICE6GAWSkT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://stackabuse.s3.amazonaws.com/media/image-reconstruction-and-denoising-with-autoencoders-in-python-and-keras-3.png)"
      ],
      "metadata": {
        "id": "L8yWh3V-Wdbt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a traditional autoencoder all units are densely connected to all other units of the previous layer. This facilitates full *visibility* between the reconstruction $\\mathbf{\\hat x}$ and the input $\\mathbf{x}$, i.e., information about $x_i$ can flow to all output positions. One drawback of this scheme is that the latent space can become *trivial*. When given enough capacity, the network can learn a simple *copy* function that simply *restates* the input condition rather than utilize *statistical* redundancies/features of the data to perform compression. In these cases, the output likelihoods are 100% for any input, meaning they fail to act as properly normalized probabilities. One way to overcome this is by enforcing autoregression. In this case, each output $\\hat x_i$ is a *conditional probability* $\\hat x_i = p_\\theta(x_i|x_1,\\dots,x_{i-1})$. Then the full reconstruction can be expressed as\n",
        "\n",
        "$$p_\\theta(\\mathbf{x}) = \\prod_{i = 1}^D p_\\theta(x_i|x_1,\\dots,x_{i-1}) = \\prod_{i=1}^D \\hat x_i.$$\n",
        "\n",
        "Since each $\\hat x_i \\in [0, 1]$, this probability will always remain valid."
      ],
      "metadata": {
        "id": "Wr50M10JXxEp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To enforce autoregressivity, we must prevent $\\hat x_i$ from accessing information about $x_{j \\ge i}$. We can do this by zeroing connections in the encoder and decoder matricies so as to prohibit non-causal paths. For example, consider an autoencoder with three input units, four hidden units, and three output units. Suppose we wish to enforce $p(x_1)p(x_2|x_1)p(x_3|x_1,x_2)$. For $\\hat x_1$ we must \"cut all ties\" since it gives an *unconditional* likelihood. For $\\hat x_2$, we only allow information from $x_1$. For $\\hat x_3$, we only allow information from $x_1$ and $x_2$. The diagram below shows the autoencoder with certain connections cut to preserve causality:\n",
        "\n",
        "![](https://i.ibb.co/t2kwPLS/MADE.png)\n",
        "\n",
        "Here, the numbers on each hidden unit denote the inputs on which it depends. In this specific scenario, the first unit of the first hidden layer depends only on $x_1$, whereas the remaining units of that layer depend on both $x_1$ and $x_2$. No unit is permitted to depend on all inputs since that would defeat the autogressive property. In the second hidden layer, we see two hidden units depending only on $x_1$, while two others depend on both $x_1$ and $x_2$. The choice of which hidden units depend on which inputs is rather subjective. The only constraint is that no hidden depends on all inputs. At the output layer, we see that $y_1 = \\hat x_1$ depends on nothing. Meanwhile, $y_2$ depends only on $x_1$ whereas $y_3$ depends only on $x_1$ and $x_2$. In the next section we describe a general masking formula."
      ],
      "metadata": {
        "id": "sAImughxav27"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2. Generating Masks"
      ],
      "metadata": {
        "id": "P6zcqNMIvZkq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To generate masks for each layer, we firstly assign each unit $z_k^l$ a number between $1$ and $D - 1$ (where $D$ is the dimensionality of the input). Denote this by $\\text{ID}^l(k)$. We then ensure that for each connection, $z_j^{l-1} \\to z_k^l$, we have that $\\text{ID}^l(k) \\ge \\text{ID}^{l-1}(j)$. At the input layer we assign the inputs IDs by $\\text{ID}^0(k) = k$. We do the same for the output layer."
      ],
      "metadata": {
        "id": "tLFP7k3Jvb6x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This inductively ensures that all units in layer $l$ will only be connected to units in layer $l-1$ having a connection to past inputs. To actually generate the masks, we simply apply the above rule for each position. Namely, the mask for the weights between layer $l-1$ and $l$ is given by\n",
        "\n",
        "$$\\mathbf{M}^{l}_{k', k} = \\begin{cases}1 & \\text{if } \\text{ID}^l(k') \\ge \\text{ID}^{l-1}(k) \\\\ 0 & \\text{otherwise}\\end{cases}.$$\n",
        "\n",
        "For the output layer we replace $\\ge$ with $\\gt$."
      ],
      "metadata": {
        "id": "LG6bGwClxFgr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Data"
      ],
      "metadata": {
        "id": "33CIYOBi9VAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Download the MNIST dataset.\n",
        "\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.PILToTensor(),\n",
        "    transforms.Lambda(lambda x: x / 255.),\n",
        "])\n",
        "\n",
        "train_dataset = MNIST(root='.', train=True, download=True, transform=transform)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ilFwX1cczg-s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "565ac04e-e3f5-4d88-9880-47b0c8819fbc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 109174753.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 76911551.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 27981208.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 14388616.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown\n",
        "\n",
        "transforms.ToPILImage()(train_dataset[0][0]).resize((200, 200), 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "cellView": "form",
        "id": "BmEorrVL0A7-",
        "outputId": "b00a6401-03ec-44a3-db27-ed7e66a09a7e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=200x200>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAAAAACIM/FCAAAC9klEQVR4nO2dTYhOURjHXx9ZECYbakpiQYlYoKQmaZJiMbGhbLBDVjZ2FqSwMLKwmrKQLVaUz4VS8rEhex87XjT5iGHxf9506na799x7p6dnfr/Nr/d+nHP/PXW63XPmTK8HAAAAAAAAAAAAAAAAAPCfWd00O0daXHTumDTffq6WjkoXpP3SD+mcdLqsx9m1n9EpBPEGQbwRJsjc7DuXS/OkrXZ0mzQk7a3QzjtpXBqTvkmvpEcVmglTEYJ4gyDeCBMk4+13o3RPKnzBrcKU+ZA0mZz8IH2W3lZoLkxFCOINgngjTJCM4XeJ9FRaWeEOu7QvbZd+2cns8TslTEUI4g2CeCNMkIyPD5+kk9Ju6YWdHE8ufSmNSvaCu1Y6Ub/nMsJUhCDeIIg3wgRpPPW2SLKPtb2r0mHpoHS9aScVCFMRgniDIN4giDfy5xCNr+nPL8mvI9INaarXIWEqQhBvEMQbYYK0vYJugXRbGpF2SXdb7ishTEUI4g2CeCNMkI4WMK+Snkt96YH0TLpil/5tp8cwFSGINwjijTBBOhp+DVuOPCEtTM6dMl+TPjbsKkxFCOINgngjTJBuh19jnXRR2pGetFnHM9L73D7CVIQg3iCIN8IEmZbh1xiS9kgT6RPcl0ZzGw9TEYJ4gyDeCBNkOofflJ9mW3vxW9opPazdXJiKEMQbBPEGQbzReAVdFdZL+6RNhT2/lh7n9hGmIgTxBkG8ESZIR8OvbSx3XLKpxGWFl/6RbA4xe5FzmIoQxBsE8UaYIG19RRkMrQck29BzRckdtpBuMHl4q+EDhKkIQbxBEG+ECZI//C6VbE+Ny3Z0TckdthfSeemmHW3pj/rCVIQg3iCIN8IEqTP82uZztuRtg1S6B90TyZbO3ZG+1+iyOmEqQhBvEMQbYYKUD79bJNtubrM0XHaHja2XpLPSZPG1rRKmIgTxBkG8ESZI+dTbWKKUN5JtU2ETaIN/39Rv+Fj1CVMRgniDIN4gCAAAAAAAAADAjOIfxWhM3nfnBlIAAAAASUVORK5CYII=\n"
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Model"
      ],
      "metadata": {
        "id": "GGm3DNh_9Yzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Mask generation.\n",
        "\n",
        "from typing import Tuple\n",
        "\n",
        "def get_layer_mask(this_layer_ids: Tuple, next_layer_ids: Tuple, is_output: bool = False) -> torch.Tensor:\n",
        "\n",
        "    this_layer_size = len(this_layer_ids)\n",
        "    next_layer_size = len(next_layer_ids)\n",
        "\n",
        "    mask = torch.ones((next_layer_size, this_layer_size))\n",
        "\n",
        "    # Zero out non-causal connections.\n",
        "\n",
        "    for i, this_id in enumerate(this_layer_ids):\n",
        "        for j, next_id in enumerate(next_layer_ids):\n",
        "\n",
        "            if is_output:\n",
        "                mask[j, i] = int(next_id > this_id)\n",
        "            else:\n",
        "                mask[j, i] = int(next_id >= this_id)\n",
        "    return mask.to(float)"
      ],
      "metadata": {
        "id": "cjVFYYX40bH2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some quick tests show that our masking code matches the diagrams in the paper."
      ],
      "metadata": {
        "id": "6z0UpETF3PzU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_layer_mask((3, 1, 2), (2, 1, 2, 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGJmBUJx1qiZ",
        "outputId": "c4b7cd62-9927-46f4-8d91-5f47dbdf8412"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1., 1.],\n",
              "        [0., 1., 0.],\n",
              "        [0., 1., 1.],\n",
              "        [0., 1., 1.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_layer_mask((2, 1, 2, 2), (1, 2, 2, 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agMQnUYS3DV1",
        "outputId": "a954fbad-c480-429a-d46d-0d7499aaca6a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1., 0., 0.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [0., 1., 0., 0.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_layer_mask((1, 2, 2, 1), (3, 1, 2), is_output=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29quuFQR3H0A",
        "outputId": "9290fd00-40fa-4a23-83a8-6abf2d9c057e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [1., 0., 0., 1.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Unit ID assignment.\n",
        "\n",
        "def get_hidden_layer_ids(layer_size: int, input_size: int) -> Tuple:\n",
        "\n",
        "    return tuple(torch.randint(low=1, high=input_size, size=(layer_size,)).tolist())"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ndmmQCC77Nv8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Model.\n",
        "\n",
        "import math\n",
        "\n",
        "\n",
        "class MaskedLinear(nn.Module):\n",
        "    \"\"\"A masked linear layer.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_features: int,\n",
        "        out_features: int,\n",
        "        input_layer_size: int,\n",
        "        previous_layer_ids: Tuple,\n",
        "        this_layer_ids: Tuple = None,\n",
        "        is_output_layer: bool = False,\n",
        "    ) -> None:\n",
        "        \"\"\"Initializes the module.\"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "\n",
        "        std = math.sqrt(2 / (in_features + out_features))\n",
        "        self.weight = nn.Parameter(std * torch.randn((out_features, in_features)))\n",
        "        self.bias = nn.Parameter(torch.zeros(out_features))\n",
        "        self.layer_ids = this_layer_ids or get_hidden_layer_ids(out_features, input_layer_size)\n",
        "\n",
        "        self.mask = get_layer_mask(previous_layer_ids, self.layer_ids, is_output=is_output_layer)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Forward pass.\"\"\"\n",
        "\n",
        "        return x @ (self.weight * self.mask).T + self.bias\n",
        "\n",
        "\n",
        "class MADE(nn.Module):\n",
        "    \"\"\"MADE.\"\"\"\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        \"\"\"Initializes the module.\"\"\"\n",
        "\n",
        "        super(MADE, self).__init__()\n",
        "\n",
        "        input_size = 28 * 28\n",
        "        hidden_size = 500\n",
        "        input_layer_ids = tuple(range(1, input_size + 1))\n",
        "\n",
        "        # Encoder.\n",
        "\n",
        "        self.linear_0 = MaskedLinear(input_size, hidden_size, input_size, input_layer_ids)\n",
        "        self.linear_1 = MaskedLinear(hidden_size, hidden_size, input_size, self.linear_0.layer_ids)\n",
        "        #self.linear_2 = MaskedLinear(hidden_size, hidden_size, input_size, self.linear_1.layer_ids)\n",
        "\n",
        "        # Decoder.\n",
        "\n",
        "        #self.linear_3 = MaskedLinear(hidden_size, hidden_size, input_size, self.linear_2.layer_ids)\n",
        "        self.linear_4 = MaskedLinear(hidden_size, hidden_size, input_size, self.linear_1.layer_ids)\n",
        "        self.linear_5 = MaskedLinear(hidden_size, input_size, input_size, self.linear_4.layer_ids, is_output_layer=True, this_layer_ids=input_layer_ids)\n",
        "\n",
        "    def encode(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Encodes an observation.\"\"\"\n",
        "\n",
        "        x = F.relu(self.linear_0(x))\n",
        "        x = F.relu(self.linear_1(x))\n",
        "        #x = F.relu(self.linear_2(x))\n",
        "\n",
        "        return x\n",
        "\n",
        "    def decode(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Decodes a latent.\"\"\"\n",
        "\n",
        "        #x = F.relu(self.linear_3(x))\n",
        "        x = F.relu(self.linear_4(x))\n",
        "        x = F.sigmoid(self.linear_5(x))\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"Forward pass.\"\"\"\n",
        "\n",
        "        z = self.encode(x)\n",
        "        y = self.decode(z)\n",
        "\n",
        "        return y, z\n",
        "\n"
      ],
      "metadata": {
        "id": "bFm2kCu4BPi0",
        "cellView": "form"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Training"
      ],
      "metadata": {
        "id": "Wqw_KiHr9bph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MADE()"
      ],
      "metadata": {
        "id": "ipb6m1C4Sx7X"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)"
      ],
      "metadata": {
        "id": "YlOzbYQ3SzLy"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "batch_size = 256\n",
        "\n",
        "train_dataloader = D.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    losses = []\n",
        "\n",
        "    for i, (x, _) in enumerate(train_dataloader):\n",
        "\n",
        "        x = x.view(-1, 28 * 28).to(float).round()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        reconstruction, _ = model(x)\n",
        "        loss = F.binary_cross_entropy(reconstruction, x)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        if (i % 10) == 0:\n",
        "            mean_loss = sum(losses) / len(losses)\n",
        "            losses.clear()\n",
        "\n",
        "            print(f'epoch {epoch}, batch {i} - loss: {mean_loss}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oQ6LWo_LSoBd",
        "outputId": "4e427c7c-736f-4316-9d5d-3e776c8c0658"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0, batch 0 - loss: 0.6933095152392282\n",
            "epoch 0, batch 10 - loss: 0.47814847788756626\n",
            "epoch 0, batch 20 - loss: 0.35502525575291377\n",
            "epoch 0, batch 30 - loss: 0.32285637736373207\n",
            "epoch 0, batch 40 - loss: 0.3027750222829761\n",
            "epoch 0, batch 50 - loss: 0.2882828122121873\n",
            "epoch 0, batch 60 - loss: 0.2802398014168271\n",
            "epoch 0, batch 70 - loss: 0.2702965959162916\n",
            "epoch 0, batch 80 - loss: 0.2611743154026297\n",
            "epoch 0, batch 90 - loss: 0.2537971390410896\n",
            "epoch 0, batch 100 - loss: 0.24683211055267612\n",
            "epoch 0, batch 110 - loss: 0.24388247088469517\n",
            "epoch 0, batch 120 - loss: 0.23744076590905117\n",
            "epoch 0, batch 130 - loss: 0.23347261721000753\n",
            "epoch 0, batch 140 - loss: 0.2305496718853422\n",
            "epoch 0, batch 150 - loss: 0.2239680907236549\n",
            "epoch 0, batch 160 - loss: 0.22254106356128908\n",
            "epoch 0, batch 170 - loss: 0.21713457531589545\n",
            "epoch 0, batch 180 - loss: 0.2140599721820206\n",
            "epoch 0, batch 190 - loss: 0.21130372489397428\n",
            "epoch 0, batch 200 - loss: 0.2075144378046748\n",
            "epoch 0, batch 210 - loss: 0.20451428861870302\n",
            "epoch 0, batch 220 - loss: 0.1976528559222188\n",
            "epoch 0, batch 230 - loss: 0.19840429311915983\n",
            "epoch 1, batch 0 - loss: 0.19897756334202416\n",
            "epoch 1, batch 10 - loss: 0.1930672207432941\n",
            "epoch 1, batch 20 - loss: 0.1903949485963434\n",
            "epoch 1, batch 30 - loss: 0.1887614077701012\n",
            "epoch 1, batch 40 - loss: 0.18986183960288333\n",
            "epoch 1, batch 50 - loss: 0.1873102119036279\n",
            "epoch 1, batch 60 - loss: 0.18498168024075226\n",
            "epoch 1, batch 70 - loss: 0.18350013581755917\n",
            "epoch 1, batch 80 - loss: 0.18054995801458965\n",
            "epoch 1, batch 90 - loss: 0.1810327531285721\n",
            "epoch 1, batch 100 - loss: 0.17968578480119496\n",
            "epoch 1, batch 110 - loss: 0.17961966626206052\n",
            "epoch 1, batch 120 - loss: 0.17598656157972886\n",
            "epoch 1, batch 130 - loss: 0.17743033007612324\n",
            "epoch 1, batch 140 - loss: 0.17490028882113587\n",
            "epoch 1, batch 150 - loss: 0.17372135629562052\n",
            "epoch 1, batch 160 - loss: 0.17300346749495246\n",
            "epoch 1, batch 170 - loss: 0.17004425230030373\n",
            "epoch 1, batch 180 - loss: 0.17210674769206188\n",
            "epoch 1, batch 190 - loss: 0.1720910242898231\n",
            "epoch 1, batch 200 - loss: 0.16916174366773942\n",
            "epoch 1, batch 210 - loss: 0.16835998827229673\n",
            "epoch 1, batch 220 - loss: 0.16564678531842558\n",
            "epoch 1, batch 230 - loss: 0.16673030588716548\n",
            "epoch 2, batch 0 - loss: 0.16267702982768426\n",
            "epoch 2, batch 10 - loss: 0.16476253011404277\n",
            "epoch 2, batch 20 - loss: 0.1634737920686869\n",
            "epoch 2, batch 30 - loss: 0.16340174326094684\n",
            "epoch 2, batch 40 - loss: 0.16239685884022295\n",
            "epoch 2, batch 50 - loss: 0.16385558540330714\n",
            "epoch 2, batch 60 - loss: 0.1623413558428171\n",
            "epoch 2, batch 70 - loss: 0.16169697874627625\n",
            "epoch 2, batch 80 - loss: 0.1613144853313373\n",
            "epoch 2, batch 90 - loss: 0.16098719466949774\n",
            "epoch 2, batch 100 - loss: 0.16033738875459796\n",
            "epoch 2, batch 110 - loss: 0.15981710190881776\n",
            "epoch 2, batch 120 - loss: 0.15841093461885927\n",
            "epoch 2, batch 130 - loss: 0.1583704019284873\n",
            "epoch 2, batch 140 - loss: 0.1589437343727959\n",
            "epoch 2, batch 150 - loss: 0.1583392538802834\n",
            "epoch 2, batch 160 - loss: 0.15848856609188167\n",
            "epoch 2, batch 170 - loss: 0.15729451462192207\n",
            "epoch 2, batch 180 - loss: 0.15520306107758383\n",
            "epoch 2, batch 190 - loss: 0.15583898032428456\n",
            "epoch 2, batch 200 - loss: 0.15588762611368262\n",
            "epoch 2, batch 210 - loss: 0.15634189626828615\n",
            "epoch 2, batch 220 - loss: 0.15485314847037374\n",
            "epoch 2, batch 230 - loss: 0.15406757026698664\n",
            "epoch 3, batch 0 - loss: 0.15392730671151256\n",
            "epoch 3, batch 10 - loss: 0.15348606078579527\n",
            "epoch 3, batch 20 - loss: 0.1511646326295872\n",
            "epoch 3, batch 30 - loss: 0.15304370800667316\n",
            "epoch 3, batch 40 - loss: 0.15070596945238957\n",
            "epoch 3, batch 50 - loss: 0.1516473850882246\n",
            "epoch 3, batch 60 - loss: 0.15144116023854876\n",
            "epoch 3, batch 70 - loss: 0.1512089485127604\n",
            "epoch 3, batch 80 - loss: 0.1514252758572161\n",
            "epoch 3, batch 90 - loss: 0.1503079737774457\n",
            "epoch 3, batch 100 - loss: 0.1497340770188846\n",
            "epoch 3, batch 110 - loss: 0.14981704299346207\n",
            "epoch 3, batch 120 - loss: 0.1517310309239185\n",
            "epoch 3, batch 130 - loss: 0.14737021450797955\n",
            "epoch 3, batch 140 - loss: 0.1518065716261902\n",
            "epoch 3, batch 150 - loss: 0.15042890661176853\n",
            "epoch 3, batch 160 - loss: 0.14873784924038885\n",
            "epoch 3, batch 170 - loss: 0.15058592583727398\n",
            "epoch 3, batch 180 - loss: 0.14724470406374873\n",
            "epoch 3, batch 190 - loss: 0.14856087972345627\n",
            "epoch 3, batch 200 - loss: 0.14769254799814552\n",
            "epoch 3, batch 210 - loss: 0.14909392371575328\n",
            "epoch 3, batch 220 - loss: 0.14831008012471114\n",
            "epoch 3, batch 230 - loss: 0.1470404709811394\n",
            "epoch 4, batch 0 - loss: 0.1486734928997089\n",
            "epoch 4, batch 10 - loss: 0.14581271945514507\n",
            "epoch 4, batch 20 - loss: 0.14498684998595635\n",
            "epoch 4, batch 30 - loss: 0.14623958537787254\n",
            "epoch 4, batch 40 - loss: 0.14457820177246852\n",
            "epoch 4, batch 50 - loss: 0.14515760686259221\n",
            "epoch 4, batch 60 - loss: 0.14539096589133743\n",
            "epoch 4, batch 70 - loss: 0.1452990952096713\n",
            "epoch 4, batch 80 - loss: 0.1449266675090612\n",
            "epoch 4, batch 90 - loss: 0.14630297135892495\n",
            "epoch 4, batch 100 - loss: 0.14612512950205217\n",
            "epoch 4, batch 110 - loss: 0.14538452014344763\n",
            "epoch 4, batch 120 - loss: 0.1439794199575914\n",
            "epoch 4, batch 130 - loss: 0.14487162733116773\n",
            "epoch 4, batch 140 - loss: 0.1440724939179104\n",
            "epoch 4, batch 150 - loss: 0.1435149995296877\n",
            "epoch 4, batch 160 - loss: 0.14425502977669868\n",
            "epoch 4, batch 170 - loss: 0.14333168495988907\n",
            "epoch 4, batch 180 - loss: 0.14371234469650104\n",
            "epoch 4, batch 190 - loss: 0.14299733991873853\n",
            "epoch 4, batch 200 - loss: 0.1431374649321699\n",
            "epoch 4, batch 210 - loss: 0.14442312865773438\n",
            "epoch 4, batch 220 - loss: 0.14455458102599958\n",
            "epoch 4, batch 230 - loss: 0.14231102874890392\n",
            "epoch 5, batch 0 - loss: 0.14655339432126868\n",
            "epoch 5, batch 10 - loss: 0.14077106414941326\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-d887e963d268>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mreconstruction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreconstruction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Evaluation"
      ],
      "metadata": {
        "id": "TjtNnGQg9dS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transforms.ToPILImage()(x[202].view(28, 28)).resize((200, 200),0)"
      ],
      "metadata": {
        "id": "bRBjQBde_g15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "70d85bdb-829f-430e-b615-3fabb7c33974"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=200x200>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAAAAACIM/FCAAABXElEQVR4nO3bwU7DMBRE0YL4/18uGzZIVWU7TjIdnbOn6dWTHiYJjwcAAAAAAAAAADf7uuIiz9UfnPh236vXSCMkjZA0NSG71+/ypn1n5EvWTERIGiFpakJ+Nn3OKWt3Rs1EhKQRkqYm5PD6nd+7I2fZ+U+tmYiQNELS1ITsOv2+tunWxnPg02omIiSNkDRC0iz8Hhk5Yl/yaPKfmokISSMkTU3IzPrN3Lt/aiYiJI2QNDUhh++ibN63y88iayYiJI2QNDUhQ+v35U688JzrDbpPJCSNkDQLp99z9u7RV/BqJiIkjZA0NSHv1+8VryW/u4Z/3/tgQtIISXPuG3TL5k/YNRMRkkZIGiFp1t+gW76Zcs7fBjUTEZJGSJqakKElesXNlKO3xmsmIiSNkDQ1IffdRdn8KLJmIkLSCElTE7KwBI+ehc95BaRmIkLSCElTEwIAAAAAAAAAwO1+Ad1lEflWvb4sAAAAAElFTkSuQmCC\n"
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transforms.ToPILImage()(model(x[202].view(-1, 28*28))[0].view(28, 28)).resize((200, 200),0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "nzRTyQ-Nb9lV",
        "outputId": "33ef1d1b-b8c5-4884-8702-d276ba6e5200"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=200x200>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAAAAACIM/FCAAAEp0lEQVR4nO2dwYtVdRzF78xrqqkxoyK1NE0JI1u1KnQxiBBI0tJFkuAqFy36G4SgXW0DF9VeaNEiN0MjKBIEiagouBDMcWp0TOzNm5nXuDjnR5zL5XqnnPz65Xw2h/ve/d53z/zgvN987+/eN9KrHhuGbW+O/l9nsdbYSDRsJBppjBhjjHkkjKzp8UY6fMiKSNW01YU0X4g2Eg0biUYaI/85fmsJOyqb3Oo1fdaK6lBkpUlaSTMiNhING4mGjURjNd8j+pXRExmrZJP7PCVv8sW/Rco3xxJkWbaWZNfaN4+SZkRsJBo2Eo00Rp5YfYmmsM7Uq3EIc/fZpl25Va4IDiALIgozuQR2LY3l4I8/NhING4lGGiOd4ndUROe7lCcr2ew1VeguTOha/N6BaE+leZmJpnCaEbGRaNhINNIY6RS/GnTMRE5JOZflPLd6G/IpZA9kXHbl0RZZMStHfRpyHfIN5EfI75V88oKcVZoRsZFo2Eg00hhpj1/tM4xJyXrIXshnrNgh9X9CTkGuQP6AlMCm7pKj8jCfQO5BzrLiN4ibD7GxkWjYSDQ6xa92cl+F7IYchGxkBVsJtyCnIb9AbkCGcrRqO4Rh+h5kVuQFSOn99qWCpBkRG4mGjUQjjZH2+GXCMVOZm89ANkNekRcLTMi7kAWp59/ur0r2eQ1yVU7rNoRhPsGKEsNCmhGxkWjYSDRsJBqdpvEMbl7KewsyCXlJK+YgnL+fgFyDzEP6ctDyP8JOyEeQA5B1kDchx1jReDt4mhGxkWjYSDTSGGmPX83dLRBG4/MQXWpcTUF+gLDdzMuFDNqBVrBDfQEyDWGL5kVIbZU1N91FiY2NRMNGotEcvyXvmLsfQI5DnoMw/bjk7TtWfAuZk3our2PglltNyFD2YW+GFx8H8olvsOJk0ymnGREbiYaNRCONkeb4LRNLdhY+hvCqH6fEU/Ie87a8qX8fXQLCw5SWNNfDbYNwhs1pL7P9Z8h07eyENCNiI9GwkWikMdLefNgPmYQwPtm75bK4eUjpx/IP03iH3bLUl0/m1PpzCC8lzkC+hnwFGbSdapoRsZFo2Eg00hjpFL/j8iJXWXwJWZT3mpdXNFL+hJzvboKwB8E28TlIlydspBkRG4mGjUQjjZH23q8+JojwetqS7qoVek/dmLzIhOWNJ9VhORHOon+F9OXFVtKMiI1Ew0aiYSPRaG9ivw7RhxBx4s5bX2a0Qp9Mx6PzGuA+yFHIy6xgT5urrc9DuJDuzoNO/x/SjIiNRMNGopHGSHsX5SJkK4Q3u7wDYWf5e0hpMOuaN259CGGDekIreEPMGTlq/4EnXifNiNhINGwkGmmMtMevhimbIRsg78tWmady2rtV6jnBZTOENx5eZgXvCvkJornbuFS5mTQjYiPRsJFopDHSfnmOFw+PQBiNh+S92v3f2yBMdebmPOQLCNd+3GQF194ty2FW8QsqJM2I2Eg0bCQaaYx0+v0RutWHz/Fhn+9COKUtFxiZrQzsS5Dy3I01Ic2I2Eg0bCQaaYz8i58RbOwI1H5GkHRZe/GQSDMiNhING4lGGiPGGGOMMcYYY4wxxhhjTFjuA2Uux2UzbOATAAAAAElFTkSuQmCC\n"
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Sample from the model.\n",
        "\n",
        "import random\n",
        "\n",
        "def sample(sample_size: int = 1):\n",
        "    input_size = 28 * 28\n",
        "    model_input = torch.zeros(sample_size, input_size).to(float)\n",
        "\n",
        "    for i in range(input_size):\n",
        "        probs = model(model_input)[0][:, : i + 1]\n",
        "        distribution = torch.distributions.Bernoulli(probs=probs)\n",
        "        model_input[:, i] = distribution.sample()[:, i]\n",
        "\n",
        "\n",
        "    return model_input"
      ],
      "metadata": {
        "id": "QXjkOOa1f6nG"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.utils import save_image\n",
        "\n",
        "s = sample(64).view(-1, 1, 28,28)\n",
        "save_image(s, './samples.png')"
      ],
      "metadata": {
        "id": "DANaYSv-vyQJ"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kcACSGN40VX1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}